{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e022a554-562c-4272-b7b2-e88cdcab03b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import se3\n",
    "import tqdm\n",
    "import h5py\n",
    "import torch\n",
    "import pycolmap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.func import jacfwd\n",
    "from torch.autograd.functional import jacobian\n",
    "from IPython.display import display\n",
    "from torch import Tensor\n",
    "\n",
    "import sfm\n",
    "import loader\n",
    "\n",
    "class SUCRe(torch.nn.Module):\n",
    "    def __init__(self, image: sfm.Image, light_model=False):\n",
    "        super().__init__()\n",
    "        self.image = image\n",
    "        self.light_model = light_model\n",
    "        self.B = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]]))\n",
    "        self.beta = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]]))\n",
    "        self.gamma = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]]))\n",
    "        if self.light_model:\n",
    "            self.cam2light = torch.nn.Parameter(torch.tensor([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], device=device))\n",
    "            self.sigma = torch.nn.Parameter(torch.eye(2, device=device))\n",
    "\n",
    "    def compute_l_z(self, cP: Tensor) -> tuple[float | Tensor, Tensor]:\n",
    "        z = cP.norm(dim=0)\n",
    "        if self.light_model:\n",
    "            R, t = se3.exp(self.cam2light)\n",
    "            Sigma = self.sigma.T @ self.sigma\n",
    "            lP = R @ cP + t\n",
    "            lp = lP[:2] / lP[2]\n",
    "            lp = lp.T.unsqueeze(dim=2)\n",
    "            l = torch.exp(-torch.flatten(lp.transpose(1, 2) @ Sigma.inverse() @ lp) / 2)\n",
    "            z += lP.norm(dim=0)\n",
    "        else:\n",
    "            l = 1.0\n",
    "        return l, z\n",
    "\n",
    "    def compute_J(self, matches_data: loader.MatchesData) -> Tensor:\n",
    "        J_numerator = torch.zeros((self.image.camera.height, self.image.camera.width, 3), device=self.B.device)\n",
    "        J_denominator = torch.zeros((self.image.camera.height, self.image.camera.width, 3), device=self.B.device)\n",
    "        \n",
    "        for u, v, cP, I in matches_data.iter(device=self.B.device):\n",
    "            l, z = self.compute_l_z(cP)\n",
    "            absorption = l * torch.exp(-self.beta * z)\n",
    "            backscatter = l * self.B * (1 - torch.exp(-self.gamma * z))\n",
    "            J_numerator[v, u] += ((I - backscatter) * absorption).T\n",
    "            J_denominator[v, u] += absorption.square().T\n",
    "        \n",
    "        J = J_numerator / J_denominator\n",
    "        return J\n",
    "\n",
    "    def forward(self, J: Tensor, u: Tensor, v: Tensor, cP: Tensor) -> Tensor:\n",
    "        l, z = self.compute_l_z(cP)\n",
    "        I_hat = l * (J[v, u].T * torch.exp(-self.beta * z) + self.B * (1 - torch.exp(-self.gamma * z)))\n",
    "        return I_hat\n",
    "\n",
    "    def plot_l(self):\n",
    "        with torch.no_grad():\n",
    "            u, v, cP = self.image.unproject_depth_map(self.image.get_depth_map().to(self.cam2light.device), to_world=False)\n",
    "            l, _ = self.compute_l_z(cP)\n",
    "            l_map = torch.zeros((self.image.camera.height, self.image.camera.width), device=l.device)\n",
    "            l_map[v, u] = l\n",
    "        return Image.fromarray(np.uint8(plt.colormaps['jet'](l_map.cpu().numpy())[:, :, :3] * 255))\n",
    "\n",
    "\n",
    "def normalize(unattenuated):\n",
    "    restored = unattenuated.detach().cpu().numpy().copy()\n",
    "    valid = np.all(~np.isnan(restored), axis=2)\n",
    "    restored_valid = restored[valid]\n",
    "    restored_valid = np.clip(restored_valid, np.percentile(restored_valid, 1, axis=0), np.percentile(restored_valid, 99, axis=0))\n",
    "    restored_valid = restored_valid - np.min(restored_valid, axis=0)\n",
    "    restored_valid = restored_valid / np.max(restored_valid, axis=0)\n",
    "    restored[~valid] = 0\n",
    "    restored[valid] = restored_valid\n",
    "    return Image.fromarray(np.uint8(restored * 255))\n",
    "\n",
    "\n",
    "device='cuda'\n",
    "num_workers = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48caaf8-6bdb-438e-8fd7-7c7981b9f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "colmap_model = sfm.COLMAPModel(\n",
    "    model_dir=Path('/media/clementin/data/Dehazing/2015/sparse/'),\n",
    "    image_dir=Path('/media/clementin/data/Dehazing/2015/images/'),\n",
    "    depth_dir=Path('/media/clementin/data/Dehazing/2015/depth_maps/'),\n",
    "    image_scale=0.25\n",
    ")\n",
    "\n",
    "image = colmap_model['20150418T030314.000Z.png']\n",
    "matches_file = loader.MatchesFile(path=Path('test/20150418T030314.000Z.h5'), colmap_model=colmap_model, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa75030-5da4-4bf4-9789-d76a882b1460",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "image.match_images(\n",
    "    image_list=list(colmap_model.images.values()),\n",
    "    matches_file=matches_file,\n",
    "    min_cover=0.01,\n",
    "    num_workers=num_workers,\n",
    "    device=device\n",
    ")\n",
    "matches_file.prepare_matches(num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c825f-d151-44d1-9820-1e7e21bf320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_file.check_integrity()\n",
    "\n",
    "matches_data = matches_file.load_matches(pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782786d-91bc-4fea-be97-dd16849a9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sucre = SUCRe(image, light_model=True)\n",
    "sucre = sucre.to(device)\n",
    "\n",
    "n_obs = len(matches_data)\n",
    "optimizer = torch.optim.Adam(sucre.parameters(), lr=0.05)\n",
    "\n",
    "costs = []\n",
    "\n",
    "for iteration in tqdm.tqdm(range(1000)):\n",
    "    cost = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        J = sucre.compute_J(matches_data)\n",
    "    \n",
    "    for u, v, cP, I in matches_data.iter(batch_size=5, device=device):\n",
    "        loss = torch.square(I - sucre(J=J, u=u, v=v, cP=cP)).sum()\n",
    "        (loss / n_obs / 3).backward()\n",
    "        cost += loss.item()\n",
    "\n",
    "    optimizer.step()\n",
    "    costs.append(cost)\n",
    "    if iteration % 25 == 0:\n",
    "        display(sucre.plot_l())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c241eb6d-a36c-4f84-8ce6-5d181e1b61c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7fa52-4d6c-4f37-84c9-13a730cd269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_residuals(Br, Bg, Bb, betar, betag, betab, gammar, gammag, gammab):\n",
    "    B = torch.stack([Br, Bg, Bb]).view(3, 1)\n",
    "    beta = torch.stack([betar, betag, betab]).view(3, 1)\n",
    "    gamma = torch.stack([gammar, gammag, gammab]).view(3, 1)\n",
    "    \n",
    "    numerator = torch.zeros((image.camera.height, image.camera.width, 3), device=device)\n",
    "    denominator = torch.zeros((image.camera.height, image.camera.width, 3), device=device)\n",
    "    for ui, vi, zi, Ii in zip(u, v, z, I):\n",
    "        absorption = torch.exp(-beta * zi)\n",
    "        backscatter = B * (1 - torch.exp(-gamma * zi))\n",
    "        Di = Ii - backscatter\n",
    "        numerator[vi.long(), ui.long()] += (Di * absorption).T\n",
    "        denominator[vi.long(), ui.long()] += absorption.square().T\n",
    "    J = numerator / denominator\n",
    "    try:\n",
    "        display(normalize(J))\n",
    "    except:\n",
    "        pass\n",
    "    cursor = 0\n",
    "    residuals = torch.zeros((3, n_obs), dtype=torch.float32, device=device)\n",
    "    for ui, vi, zi, Ii in zip(u, v, z, I):\n",
    "        length = ui.shape[0]\n",
    "        residuals[:, cursor: cursor + length] = Ii - J[vi.long(), ui.long()].T * torch.exp(-beta * zi) - B * (1 - torch.exp(-gamma * zi))\n",
    "        cursor += length\n",
    "    return residuals.flatten()\n",
    "\n",
    "Br_hat = torch.tensor(0.1, device=device)\n",
    "Bg_hat = torch.tensor(0.1, device=device)\n",
    "Bb_hat = torch.tensor(0.1, device=device)\n",
    "betar_hat = torch.tensor(0.1, device=device)\n",
    "betag_hat = torch.tensor(0.1, device=device)\n",
    "betab_hat = torch.tensor(0.1, device=device)\n",
    "gammar_hat = torch.tensor(0.1, device=device)\n",
    "gammag_hat = torch.tensor(0.1, device=device)\n",
    "gammab_hat = torch.tensor(0.1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a3c1d-331b-445d-bf16-207d389a1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "damping = 0.1\n",
    "eye = torch.eye(9, dtype=torch.float32, device=device)\n",
    "previous_cost = torch.inf\n",
    "\n",
    "for _ in range(100):\n",
    "    res = compute_residuals(Br_hat, Bg_hat, Bb_hat, betar_hat, betag_hat, betab_hat, gammar_hat, gammag_hat, gammab_hat)\n",
    "    jac = torch.stack(\n",
    "        torch.func.jacfwd(compute_residuals, argnums=(0, 1, 2, 3, 4, 5, 6, 7, 8))(Br_hat, Bg_hat, Bb_hat, betar_hat, betag_hat, betab_hat, gammar_hat, gammag_hat, gammab_hat)\n",
    "    ).T\n",
    "    delta = torch.inverse(jac.T @ jac + damping * eye) @ (jac.T @ res)\n",
    "    Br_hat -= delta[0]\n",
    "    Bg_hat -= delta[1]\n",
    "    Bb_hat -= delta[2]\n",
    "    betar_hat -= delta[3]\n",
    "    betag_hat -= delta[4]\n",
    "    betab_hat -= delta[5]\n",
    "    gammar_hat -= delta[6]\n",
    "    gammag_hat -= delta[7]\n",
    "    gammab_hat -= delta[8]\n",
    "    cost = torch.square(res).sum().item()\n",
    "    if cost < previous_cost:\n",
    "        damping = max(damping / 10, 1e-32)\n",
    "    else:\n",
    "        damping *= 10\n",
    "    previous_cost = cost\n",
    "    print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3854a-6aaf-45a6-99b7-e665dcf52676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_residuals(B, beta, gamma):\n",
    "    numerator = torch.zeros((image.camera.height, image.camera.width), device=device)\n",
    "    denominator = torch.zeros((image.camera.height, image.camera.width), device=device)\n",
    "    for ui, vi, zi, Ii in zip(u, v, z, I):\n",
    "        absorption = torch.exp(-beta * zi)\n",
    "        backscatter = B * (1 - torch.exp(-gamma * zi))\n",
    "        Di = Ii[2] - backscatter\n",
    "        numerator[vi.long(), ui.long()] += Di * absorption\n",
    "        denominator[vi.long(), ui.long()] += absorption.square()\n",
    "    J = numerator / denominator\n",
    "    cost = 0\n",
    "    for ui, vi, zi, Ii in zip(u, v, z, I):\n",
    "        cost += torch.square(Ii[2] - J[vi.long(), ui.long()] * torch.exp(-beta * zi) - B * (1 - torch.exp(-gamma * zi))).sum()\n",
    "    return cost\n",
    "\n",
    "B_hat = torch.tensor(0.1, device=device)\n",
    "beta_hat = torch.tensor(0.1, device=device)\n",
    "gamma_hat = torch.tensor(0.1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a36f30-1152-4bde-9560-7101891e97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    res = compute_residuals(B_hat, beta_hat, gamma_hat)\n",
    "    print(res.item())\n",
    "    jac = torch.func.jacrev(compute_residuals, argnums=(0, 1, 2))(B_hat, beta_hat, gamma_hat)\n",
    "    delta = res / torch.stack(jac)\n",
    "    B_hat -= delta[0]\n",
    "    beta_hat -= delta[1]\n",
    "    gamma_hat -= delta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab126e5-673d-4761-b0ef-f5f5d2d92a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    print(compute_residuals(B_hat, beta_hat, gamma_hat).item())\n",
    "    jac = torch.func.jacrev(compute_residuals, argnums=(0, 1, 2))(B_hat, beta_hat, gamma_hat)\n",
    "    hess = torch.func.hessian(compute_residuals, argnums=(0, 1, 2))(B_hat, beta_hat, gamma_hat)\n",
    "    delta = torch.tensor(hess).inverse() @ torch.tensor(jac)\n",
    "    B_hat += delta[0]\n",
    "    beta_hat += delta[1]\n",
    "    gamma_hat += delta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78ec9a-199a-4802-a558-bf3724570440",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(hess).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9f851-b973-471b-9a43-d0f3d1b5b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(hess).T.inverse() @ torch.tensor(jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40076ed6-7bb5-414a-a6ef-038263f45e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "damping = 0.1\n",
    "eye = torch.eye(3, dtype=torch.float32, device=device)\n",
    "previous_cost = torch.inf\n",
    "\n",
    "for _ in range(100):\n",
    "    res = compute_residuals(B_hat, beta_hat, gamma_hat)\n",
    "    jac = torch.stack(\n",
    "        torch.func.jacfwd(compute_residuals, argnums=(0, 1, 2))(B_hat, beta_hat, gamma_hat)\n",
    "    ).T\n",
    "    delta = torch.inverse(jac.T @ jac  + damping * eye) @ (jac.T @ res)\n",
    "    B_hat -= delta[0]\n",
    "    beta_hat -= delta[1]\n",
    "    gamma_hat -= delta[2]\n",
    "    cost = torch.square(res).sum().item()\n",
    "    if cost < previous_cost:\n",
    "        damping = max(damping / 10, 1e-32)\n",
    "    else:\n",
    "        damping *= 10\n",
    "    previous_cost = cost\n",
    "    print(cost, B_hat.item(), beta_hat.item(), gamma_hat.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f57ff7b-1cfe-4a2d-82cf-0c1d015852d0",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd73f1-0c53-4e67-817f-764872b9146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]], device=device))\n",
    "beta = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]], device=device))\n",
    "gamma = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]], device=device))\n",
    "\n",
    "optimizer = torch.optim.Adam([B, beta, gamma], lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443043ec-0310-4e06-801c-a12519df0516",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(1000):\n",
    "    cost = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        numerator = torch.zeros((image.camera.height, image.camera.width, 3), device=device)\n",
    "        denominator = torch.zeros((image.camera.height, image.camera.width, 3), device=device)\n",
    "        for ui, vi, zi, Ii in zip(u, v, z, I):\n",
    "            ui, vi, zi, Ii = ui.to(device).long(), vi.to(device).long(), zi.to(device), Ii.to(device)\n",
    "            absorption = torch.exp(-beta * zi)\n",
    "            backscatter = B * (1 - torch.exp(-gamma * zi))\n",
    "            Di = Ii - backscatter\n",
    "            numerator[vi.long(), ui.long()] += (Di * absorption).T\n",
    "            denominator[vi.long(), ui.long()] += absorption.square().T\n",
    "        J = numerator / denominator\n",
    "\n",
    "    for ui, vi, zi, Ii in zip(u, v, z, I):\n",
    "        ui, vi, zi, Ii = ui.to(device).long(), vi.to(device).long(), zi.to(device), Ii.to(device)\n",
    "        loss = torch.square(\n",
    "            Ii - J[vi.long(), ui.long()].T * torch.exp(-beta * zi) - B * (1 - torch.exp(-gamma * zi))\n",
    "        ).sum()\n",
    "        (loss / n_obs / 3).backward()\n",
    "        cost += loss.item()\n",
    "\n",
    "    optimizer.step()\n",
    "    if iteration % 1 == 0:\n",
    "        print(cost)\n",
    "        display(normalize(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e4611-8b66-4a05-87f3-01c02bd2c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = torch.nn.Parameter(image.get_rgb().to(device))\n",
    "with torch.no_grad():\n",
    "    J[image.get_depth_map() <= 0] = torch.nan\n",
    "B = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]], device=device))\n",
    "beta = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]], device=device))\n",
    "gamma = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]], device=device))\n",
    "\n",
    "optimizer = torch.optim.Adam([J, B, beta, gamma], lr=0.05)\n",
    "\n",
    "for iteration in range(100):\n",
    "    cost = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for ui, vi, zi, Ii in zip(u, v, z, I):\n",
    "        ui, vi, zi, Ii = ui.to(device).long(), vi.to(device).long(), zi.to(device), Ii.to(device)\n",
    "        loss = torch.square(\n",
    "            Ii - J[vi.long(), ui.long()].T * torch.exp(-beta * zi) - B * (1 - torch.exp(-gamma * zi))\n",
    "        ).sum()\n",
    "        (loss / n_obs / 3).backward()\n",
    "        cost += loss.item()\n",
    "\n",
    "    optimizer.step()\n",
    "    if iteration % 1 == 0:\n",
    "        print(cost)\n",
    "        display(normalize(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ff9ac-0a34-431a-a80e-13b5f83aaa41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
