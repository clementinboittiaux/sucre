{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd7935f-ab09-4ad5-8aa5-ee9f602d88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfm\n",
    "import tqdm\n",
    "import h5py\n",
    "import torch\n",
    "import loader\n",
    "import matplotlib\n",
    "import normalization\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torch import Tensor\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class VignettingData:\n",
    "    def __init__(self):\n",
    "        self.data: list[dict[str, Tensor]] = []\n",
    "\n",
    "    def append(self, u: Tensor, v: Tensor, cP: Tensor, z: Tensor, I: Tensor):\n",
    "        self.data.append({'u': u, 'v': v, 'z': z, 'I': I, 'cP':cP})\n",
    "\n",
    "    def iterbatch(self, batch_size: int) -> tuple[Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
    "        for i in range(0, len(self.data), batch_size):\n",
    "            yield (\n",
    "                torch.hstack([sample['u'] for sample in self.data[i:i + batch_size]]).long(),\n",
    "                torch.hstack([sample['v'] for sample in self.data[i:i + batch_size]]).long(),\n",
    "                torch.hstack([sample['z'] for sample in self.data[i:i + batch_size]]),\n",
    "                torch.hstack([sample['I'] for sample in self.data[i:i + batch_size]]),\n",
    "                torch.hstack([sample['cP'] for sample in self.data[i:i + batch_size]])\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum([sample['I'].shape[0] for sample in self.data])\n",
    "\n",
    "\n",
    "def se3_exp(pose: Tensor) -> tuple[Tensor, Tensor]:\n",
    "    w1, w2, w3, p1, p2, p3 = pose\n",
    "    zero = torch.zeros_like(w1)\n",
    "    pose = torch.stack([zero, -w3, w2, p1, w3, zero, -w1, p2, -w2, w1, zero, p3, zero, zero, zero, zero])\n",
    "    pose = torch.matrix_exp(pose.view(4, 4))\n",
    "    return pose[:3, :3], pose[:3, 3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db56846-aeb2-4a49-82b7-fb33ade753fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('viewsynthesis/')\n",
    "num_workers = 32\n",
    "device='cuda:1'\n",
    "\n",
    "filter_image_names = Path('/workspace/TourEiffelClean/2015/dehazing/viewsynthesis/imagelist.txt').read_text().splitlines()\n",
    "\n",
    "colmap_model = sfm.COLMAPModel(\n",
    "    image_dir=Path('/workspace/TourEiffelClean/2015/dehazing/undistort/images/'),\n",
    "    depth_dir=Path('/workspace/TourEiffelClean/2015/dehazing/viewsynthesis/depth_maps/'),\n",
    "    model_dir=Path('/workspace/TourEiffelClean/2015/dehazing/viewsynthesis/colmap/')\n",
    ")\n",
    "\n",
    "image_list = list(colmap_model.images.values())\n",
    "image_list = [im for im in image_list if im.name not in filter_image_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655536c1-e190-46e6-9dd3-6168d2904f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in filter_image_names[51:52]:\n",
    "    image = colmap_model[image_name]\n",
    "    \n",
    "    matches_path = (output_dir / image_name).with_suffix('.h5')\n",
    "    matches_file = loader.MatchesFile(matches_path, overwrite=True)\n",
    "    \n",
    "    image.match_images(\n",
    "        image_list=image_list,\n",
    "        matches_file=matches_file,\n",
    "        min_cover=0.00001,\n",
    "        num_workers=num_workers,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    matches_file.prepare_matches(colmap_model=colmap_model, num_workers=num_workers, device=device)\n",
    "    \n",
    "    data = VignettingData()\n",
    "\n",
    "    with h5py.File(matches_path, 'r', libver='latest') as f:\n",
    "        for group in f.values():\n",
    "\n",
    "            z = torch.tensor(group['z'][()], device=device)\n",
    "            u2 = torch.tensor(group['u2'][()], device=device) + 0.5\n",
    "            v2 = torch.tensor(group['v2'][()], device=device) + 0.5\n",
    "            cP = image.camera.K_inv.to(device) @ torch.vstack([u2, v2, torch.ones_like(u2)])\n",
    "            cP = cP / cP.norm(dim=0) * z\n",
    "\n",
    "            data.append(\n",
    "                u=torch.tensor(group['u1'][()], device=device),\n",
    "                v=torch.tensor(group['v1'][()], device=device),\n",
    "                z=z,\n",
    "                I=torch.tensor(group['I'][()], device=device),\n",
    "                cP=cP\n",
    "            )\n",
    "    \n",
    "    J = torch.nn.Parameter(torch.ones((image.camera.height, image.camera.width, 3), dtype=torch.float32, device=device))\n",
    "    B = torch.nn.Parameter(torch.tensor([[0.25], [0.25], [0.25]], dtype=torch.float32, device=device))\n",
    "    beta = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]], dtype=torch.float32, device=device))\n",
    "    gamma = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]], dtype=torch.float32, device=device))\n",
    "\n",
    "    s_T_c = torch.nn.Parameter(torch.tensor([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=torch.float32, device=device))\n",
    "    halostdx = torch.nn.Parameter(torch.tensor(1.0, dtype=torch.float32, device=device))\n",
    "    halostdy = torch.nn.Parameter(torch.tensor(1.0, dtype=torch.float32, device=device))\n",
    "    halocovxy = torch.nn.Parameter(torch.tensor(0.0, dtype=torch.float32, device=device))\n",
    "\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': [J], 'lr': 0.05},\n",
    "        {'params': [B, beta, gamma, s_T_c, halostdx, halostdy, halocovxy], 'lr': 0.05}\n",
    "    ])\n",
    "    \n",
    "    size = len(data)\n",
    "\n",
    "    for iteration in tqdm.tqdm(range(1000)):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        s_R_c, s_t_c = se3_exp(s_T_c)\n",
    "        halocov = torch.stack([halostdx.square(), halocovxy, halocovxy, halostdy.square()]).view(2, 2)\n",
    "\n",
    "        for ui, vi, zi, Ii, ciP in data.iterbatch(batch_size=5):\n",
    "\n",
    "            siP = s_R_c @ ciP + s_t_c\n",
    "            sip = siP[:2] / siP[2]\n",
    "\n",
    "            sip = sip.T.unsqueeze(dim=2)\n",
    "            halo = torch.exp(-(sip.transpose(1, 2) @ halocov.inverse() @ sip).flatten() / 2)\n",
    "\n",
    "            zi = zi + siP.norm(dim=0)\n",
    "\n",
    "            loss = torch.square(\n",
    "                Ii - halo * (J[vi, ui].T * torch.exp(-beta * zi) + B * (1 - torch.exp(-gamma * zi)))\n",
    "            ).sum() / size / 3\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        s_R_c, s_t_c = se3_exp(s_T_c)\n",
    "        halocov = torch.stack([halostdx.square(), halocovxy, halocovxy, halostdy.square()]).view(2, 2)\n",
    "\n",
    "        im = J.cpu().numpy().copy()\n",
    "        valid = loader.load_depth(image.depth_path).numpy() > 0\n",
    "        image_valid = im[valid]\n",
    "        image_valid = np.clip(image_valid, np.percentile(image_valid, 1, axis=0), np.percentile(image_valid, 99, axis=0))\n",
    "        image_valid = image_valid - np.min(image_valid, axis=0)\n",
    "        image_valid = image_valid / np.max(image_valid, axis=0)\n",
    "        im[~valid] = 0\n",
    "        im[valid] = image_valid\n",
    "        im = Image.fromarray(np.uint8(im * 255))\n",
    "        im.save(output_dir / f'sucre_{image_name}')\n",
    "\n",
    "        u, v, cP = image.unproject_depth_map(loader.load_depth(image.depth_path), transform=False)\n",
    "        sP = s_R_c.cpu() @ cP + s_t_c.cpu()\n",
    "        sp = sP[:2] / sP[2]\n",
    "        sp = sp.T.unsqueeze(dim=2)\n",
    "        hl = torch.exp(-(sp.transpose(1, 2) @ halocov.cpu().inverse() @ sp).flatten() / 2)\n",
    "        hl_image = torch.zeros((image.camera.height, image.camera.width))\n",
    "        hl_image[v, u] = hl\n",
    "        Image.fromarray(np.uint8(plt.colormaps['jet'](hl_image)[:, :, :3] * 255)).save(output_dir / f'halo_{image_name}')\n",
    "        \n",
    "        depth_map = loader.load_depth(image.depth_path)\n",
    "        depth_map[~valid] = 100000\n",
    "        u, v, cP = image.unproject_depth_map(depth_map, transform=False)\n",
    "        sP = s_R_c.cpu() @ cP + s_t_c.cpu()\n",
    "        sp = sP[:2] / sP[2]\n",
    "        sp = sp.T.unsqueeze(dim=2)\n",
    "        hl = torch.exp(-(sp.transpose(1, 2) @ halocov.cpu().inverse() @ sp).flatten() / 2)\n",
    "        zih = cP.norm(dim=0) + sP.norm(dim=0)\n",
    "        rec = (hl * (J[v, u].T.cpu() * torch.exp(-beta.cpu() * zih) + B.cpu() * (1 - torch.exp(-gamma.cpu() * zih)))).T\n",
    "        rec_image = torch.zeros((image.camera.height, image.camera.width, 3))\n",
    "        rec_image[v, u] = rec.clip(0, 1)\n",
    "        Image.fromarray(np.uint8(rec_image * 255)).save(output_dir / f'reconstructed_{image_name}')\n",
    "    \n",
    "    matches_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4344e-32fd-45aa-8028-dfd5d2357500",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'B': B.detach().cpu(),\n",
    "    'beta': beta.detach().cpu(),\n",
    "    'gamma': gamma.detach().cpu(),\n",
    "    's_T_c': s_T_c.detach().cpu(),\n",
    "    'halostdx': halostdx.detach().cpu(),\n",
    "    'halostdy': halostdy.detach().cpu(),\n",
    "    'halocovxy': halocovxy.detach().cpu()\n",
    "}, 'frame000052.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d8e70e-c4bb-4757-b7ef-40bd2bbba9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = torch.load('frame000052.pt')\n",
    "B = parameters['B'].to(device)\n",
    "beta = parameters['beta'].to(device)\n",
    "gamma = parameters['gamma'].to(device)\n",
    "s_T_c = parameters['s_T_c'].to(device)\n",
    "halostdx = parameters['halostdx'].to(device)\n",
    "halostdy = parameters['halostdy'].to(device)\n",
    "halocovxy = parameters['halocovxy'].to(device)\n",
    "\n",
    "for image_name in filter_image_names:\n",
    "    image = colmap_model[image_name]\n",
    "    \n",
    "    matches_path = (output_dir / image_name).with_suffix('.h5')\n",
    "    matches_file = loader.MatchesFile(matches_path, overwrite=True)\n",
    "    \n",
    "    image.match_images(\n",
    "        image_list=image_list,\n",
    "        matches_file=matches_file,\n",
    "        min_cover=0.00001,\n",
    "        num_workers=num_workers,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    matches_file.prepare_matches(colmap_model=colmap_model, num_workers=num_workers, device=device)\n",
    "    \n",
    "    data = VignettingData()\n",
    "\n",
    "    with h5py.File(matches_path, 'r', libver='latest') as f:\n",
    "        for group in f.values():\n",
    "\n",
    "            z = torch.tensor(group['z'][()], device=device)\n",
    "            u2 = torch.tensor(group['u2'][()], device=device) + 0.5\n",
    "            v2 = torch.tensor(group['v2'][()], device=device) + 0.5\n",
    "            cP = image.camera.K_inv.to(device) @ torch.vstack([u2, v2, torch.ones_like(u2)])\n",
    "            cP = cP / cP.norm(dim=0) * z\n",
    "\n",
    "            data.append(\n",
    "                u=torch.tensor(group['u1'][()], device=device),\n",
    "                v=torch.tensor(group['v1'][()], device=device),\n",
    "                z=z,\n",
    "                I=torch.tensor(group['I'][()], device=device),\n",
    "                cP=cP\n",
    "            )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        s_R_c, s_t_c = se3_exp(s_T_c)\n",
    "        halocov = torch.stack([halostdx.square(), halocovxy, halocovxy, halostdy.square()]).view(2, 2)\n",
    "\n",
    "        numerator = torch.zeros(image.camera.height, image.camera.width, 3, dtype=torch.float32, device=device)\n",
    "        denominator = torch.zeros(image.camera.height, image.camera.width, 3, dtype=torch.float32, device=device)\n",
    "\n",
    "        for ui, vi, zi, Ii, ciP in data.iterbatch(batch_size=1):\n",
    "\n",
    "            siP = s_R_c @ ciP + s_t_c\n",
    "            sip = siP[:2] / siP[2]\n",
    "\n",
    "            sip = sip.T.unsqueeze(dim=2)\n",
    "            halo = torch.exp(-(sip.transpose(1, 2) @ halocov.inverse() @ sip).flatten() / 2)\n",
    "\n",
    "            zi = zi + siP.norm(dim=0)\n",
    "\n",
    "            Di = Ii - halo * B * (1 - torch.exp(-gamma * zi))\n",
    "            alphai = halo * torch.exp(-beta * zi)\n",
    "\n",
    "            numerator[vi, ui] += (alphai * Di).T\n",
    "            denominator[vi, ui] += torch.square(alphai).T\n",
    "\n",
    "        J = numerator / denominator\n",
    "\n",
    "        im = J.cpu().numpy().copy()\n",
    "        valid = np.all(~np.isnan(im), axis=2)\n",
    "        image_valid = im[valid]\n",
    "        image_valid = np.clip(image_valid, np.percentile(image_valid, 1, axis=0), np.percentile(image_valid, 99, axis=0))\n",
    "        image_valid = image_valid - np.min(image_valid, axis=0)\n",
    "        image_valid = image_valid / np.max(image_valid, axis=0)\n",
    "        im[~valid] = 0\n",
    "        im[valid] = image_valid\n",
    "        im = Image.fromarray(np.uint8(im * 255))\n",
    "        im.save(output_dir / f'sucre_{image_name}')\n",
    "\n",
    "        J[~valid] = 0\n",
    "\n",
    "        depth_map = loader.load_depth(image.depth_path)\n",
    "        valid = depth_map > 0\n",
    "        depth_map[~valid] = 100000\n",
    "        u, v, cP = image.unproject_depth_map(depth_map, transform=False)\n",
    "        sP = s_R_c.cpu() @ cP + s_t_c.cpu()\n",
    "        sp = sP[:2] / sP[2]\n",
    "        sp = sp.T.unsqueeze(dim=2)\n",
    "        hl = torch.exp(-(sp.transpose(1, 2) @ halocov.cpu().inverse() @ sp).flatten() / 2)\n",
    "        zih = cP.norm(dim=0) + sP.norm(dim=0)\n",
    "        rec = (hl * (J[v, u].T.cpu() * torch.exp(-beta.cpu() * zih) + B.cpu() * (1 - torch.exp(-gamma.cpu() * zih)))).T\n",
    "        rec_image = torch.zeros((image.camera.height, image.camera.width, 3))\n",
    "        rec_image[v, u] = rec.clip(0, 1)\n",
    "        Image.fromarray(np.uint8(rec_image * 255)).save(output_dir / f'reconstructed_{image_name}')\n",
    "        \n",
    "    matches_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8d13b-a804-4479-8eff-9ec8bd2f8ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
