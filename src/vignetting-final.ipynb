{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd7935f-ab09-4ad5-8aa5-ee9f602d88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfm\n",
    "import tqdm\n",
    "import h5py\n",
    "import torch\n",
    "import loader\n",
    "import matplotlib\n",
    "import normalization\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torch import Tensor\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class VignettingData:\n",
    "    def __init__(self):\n",
    "        self.data: list[dict[str, Tensor]] = []\n",
    "\n",
    "    def append(self, u: Tensor, v: Tensor, cP: Tensor, z: Tensor, I: Tensor):\n",
    "        self.data.append({'u': u, 'v': v, 'z': z, 'I': I, 'cP':cP})\n",
    "\n",
    "    def iterbatch(self, batch_size: int) -> tuple[Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
    "        for i in range(0, len(self.data), batch_size):\n",
    "            yield (\n",
    "                torch.hstack([sample['u'] for sample in self.data[i:i + batch_size]]).long(),\n",
    "                torch.hstack([sample['v'] for sample in self.data[i:i + batch_size]]).long(),\n",
    "                torch.hstack([sample['z'] for sample in self.data[i:i + batch_size]]),\n",
    "                torch.hstack([sample['I'] for sample in self.data[i:i + batch_size]]),\n",
    "                torch.hstack([sample['cP'] for sample in self.data[i:i + batch_size]])\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum([sample['I'].shape[0] for sample in self.data])\n",
    "\n",
    "\n",
    "def se3_exp(pose: Tensor) -> tuple[Tensor, Tensor]:\n",
    "    w1, w2, w3, p1, p2, p3 = pose\n",
    "    zero = torch.zeros_like(w1)\n",
    "    pose = torch.stack([zero, -w3, w2, p1, w3, zero, -w1, p2, -w2, w1, zero, p3, zero, zero, zero, zero])\n",
    "    pose = torch.matrix_exp(pose.view(4, 4))\n",
    "    return pose[:3, :3], pose[:3, 3:4]\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times\"\n",
    "matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'custom'\n",
    "matplotlib.rcParams['mathtext.rm'] = 'Times'\n",
    "matplotlib.rcParams['mathtext.it'] = 'Times:italic'\n",
    "matplotlib.rcParams['mathtext.bf'] = 'Times:bold'\n",
    "\n",
    "font = ImageFont.truetype('times', 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db56846-aeb2-4a49-82b7-fb33ade753fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"colmap = sfm.COLMAPModel(\n",
    "    image_dir=Path('/workspace/Varos/images/'),\n",
    "    depth_dir=Path('/workspace/Varos/depth_maps/'),\n",
    "    model_dir=Path('/workspace/Varos/sparse/')\n",
    ")\n",
    "\n",
    "image = colmap['seq01_veh0_camM0_A-00000318.png']\n",
    "\n",
    "matches_path = Path('test/seq01_veh0_camM0_A-00000318.h5')\"\"\"\n",
    "\n",
    "\"\"\"colmap = sfm.COLMAPModel(\n",
    "    image_dir=Path('/workspace/AQUALOC/raw_data/colmap_sequence_10/undistorted/images/'),\n",
    "    depth_dir=Path('/workspace/AQUALOC/raw_data/colmap_sequence_10/undistorted/depth_maps/'),\n",
    "    model_dir=Path('/workspace/AQUALOC/raw_data/colmap_sequence_10/undistorted/sparse/')\n",
    ")\"\"\"\n",
    "\n",
    "# image = colmap['frame012760.png']\n",
    "# matches_path = Path('test/frame012760.h5')\n",
    "\n",
    "# image = colmap['frame005980.png']\n",
    "# matches_path = Path('test/frame005980.h5')\n",
    "\n",
    "# image = colmap['frame001580.png']\n",
    "# matches_path = Path('test/frame001580.h5')\n",
    "\n",
    "colmap = sfm.COLMAPModel(\n",
    "    image_dir=Path('/workspace/TourEiffelClean/2015/dehazing/undistort/images/'),\n",
    "    depth_dir=Path('/workspace/TourEiffelClean/2015/dehazing/undistort/depth_maps/'),\n",
    "    model_dir=Path('/workspace/TourEiffelClean/2015/dehazing/undistort/sparse/')\n",
    ")\n",
    "\n",
    "# image = colmap['20150418T014923.000Z.png']\n",
    "# matches_path = Path('test/20150418T014923.000Z.h5')\n",
    "\n",
    "image = colmap['20150418T025347.000Z.png']\n",
    "matches_path = Path('test/20150418T025347.000Z.h5')\n",
    "\n",
    "# image = colmap['20150419T033711.000Z.png']\n",
    "# matches_path = Path('test/20150419T033711.000Z.h5')\n",
    "\n",
    "# image = colmap['20150419T035320.000Z.png']\n",
    "# matches_path = Path('test/20150419T035320.000Z.h5')\n",
    "\n",
    "# image = colmap['20150418T034032.000Z.png']\n",
    "# matches_path = Path('test/20150418T034032.000Z.h5')\n",
    "\n",
    "# image = colmap['20150419T033302.000Z.png']\n",
    "# matches_path = Path('test/20150419T033302.000Z.h5')\n",
    "\n",
    "\"\"\"colmap = sfm.COLMAPModel(\n",
    "    image_dir=Path('/workspace/Eurydice/sfm/pixsfm/undistort/images/'),\n",
    "    depth_dir=Path('/workspace/Eurydice/sfm/pixsfm/undistort/depth_maps/'),\n",
    "    model_dir=Path('/workspace/Eurydice/sfm/pixsfm/undistort/sparse/')\n",
    ")\n",
    "\n",
    "image = colmap['20220420T124924.000Z.png']\n",
    "\n",
    "matches_path = Path('test/20220420T124924.000Z.h5')\"\"\"\n",
    "\n",
    "\"\"\"colmap = sfm.COLMAPModel(\n",
    "    image_dir=Path('/workspace/Jaureguiberry/undistort/images/'),\n",
    "    depth_dir=Path('/workspace/Jaureguiberry/undistort/depth_maps/'),\n",
    "    model_dir=Path('/workspace/Jaureguiberry/undistort/sparse/')\n",
    ")\n",
    "\n",
    "image = colmap['frame00016124.png']\n",
    "matches_path = Path('test/frame00016124.h5')\"\"\"\n",
    "\n",
    "device='cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90591228-5b6e-4ecb-ab22-5840c2505dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = VignettingData()\n",
    "\n",
    "with h5py.File(matches_path, 'r', libver='latest') as f:\n",
    "    for group in f.values():\n",
    "\n",
    "        z = torch.tensor(group['z'][()], device=device)\n",
    "        u2 = torch.tensor(group['u2'][()], device=device) + 0.5\n",
    "        v2 = torch.tensor(group['v2'][()], device=device) + 0.5\n",
    "        cP = image.camera.K_inv.to(device) @ torch.vstack([u2, v2, torch.ones_like(u2)])\n",
    "        cP = cP / cP.norm(dim=0) * z\n",
    "\n",
    "        data.append(\n",
    "            u=torch.tensor(group['u1'][()], device=device),\n",
    "            v=torch.tensor(group['v1'][()], device=device),\n",
    "            z=z,\n",
    "            I=torch.tensor(group['I'][()], device=device),\n",
    "            cP=cP\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a50ee-6e3f-44c0-8672-ce35903875d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = torch.nn.Parameter(loader.load_image(image.image_path).to(device))\n",
    "B = torch.nn.Parameter(torch.tensor([[0.25], [0.25], [0.25]], dtype=torch.float32, device=device))\n",
    "beta = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]], dtype=torch.float32, device=device))\n",
    "gamma = torch.nn.Parameter(torch.tensor([[0.1], [0.1], [0.1]], dtype=torch.float32, device=device))\n",
    "\n",
    "s_T_c = torch.nn.Parameter(torch.tensor([0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=torch.float32, device=device))\n",
    "halostdx = torch.nn.Parameter(torch.tensor(1.0, dtype=torch.float32, device=device))\n",
    "halostdy = torch.nn.Parameter(torch.tensor(1.0, dtype=torch.float32, device=device))\n",
    "halocovxy = torch.nn.Parameter(torch.tensor(0.0, dtype=torch.float32, device=device))\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': [J], 'lr': 0.05},\n",
    "    {'params': [B, beta, gamma, s_T_c, halostdx, halostdy, halocovxy], 'lr': 0.05}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ef306-f2f2-4ff1-a3f5-e5e8f0e90d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size = len(data)\n",
    "costs = []\n",
    "\n",
    "Rs, ts = [], []\n",
    "\n",
    "for iteration in tqdm.tqdm(range(1001)):\n",
    "\n",
    "    cost = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    s_R_c, s_t_c = se3_exp(s_T_c)\n",
    "    Rs.append(s_R_c.detach().cpu().numpy())\n",
    "    ts.append(s_t_c.detach().cpu().numpy())\n",
    "    halocov = torch.stack([halostdx.square(), halocovxy, halocovxy, halostdy.square()]).view(2, 2)\n",
    "    \n",
    "    if iteration % 1 == 0:\n",
    "        im = J.detach().cpu().numpy().copy()\n",
    "        valid = loader.load_depth(image.depth_path).numpy() > 0\n",
    "        image_valid = im[valid]\n",
    "        image_valid = np.clip(image_valid, np.percentile(image_valid, 1, axis=0), np.percentile(image_valid, 99, axis=0))\n",
    "        image_valid = image_valid - np.min(image_valid, axis=0)\n",
    "        image_valid = image_valid / np.max(image_valid, axis=0)\n",
    "        im[~valid] = 0\n",
    "        im[valid] = image_valid\n",
    "        im = Image.fromarray(np.uint8(im * 255))\n",
    "        draw = ImageDraw.Draw(im)\n",
    "        draw.text((15, 0), f'Iteration {iteration:02d}', (255, 255, 255), font=font, anchor='la')\n",
    "        im.save(f'20150419T033711/frame{iteration+1:05d}.png')\n",
    "\n",
    "        u, v, cP = image.unproject_depth_map(loader.load_depth(image.depth_path), transform=False)\n",
    "        sP = s_R_c.detach().cpu() @ cP + s_t_c.detach().cpu()\n",
    "        sp = sP[:2] / sP[2]\n",
    "        sp = sp.T.unsqueeze(dim=2)\n",
    "        hl = torch.exp(-(sp.transpose(1, 2) @ halocov.detach().cpu().inverse() @ sp).flatten() / 2)\n",
    "        # hl = 1.0\n",
    "        hl_image = torch.zeros((image.camera.height, image.camera.width))\n",
    "        hl_image[v, u] = hl\n",
    "        Image.fromarray(np.uint8(plt.colormaps['jet'](hl_image)[:, :, :3] * 255)).save(f'20150419T033711/halo{iteration+1:05d}.png')\n",
    "        \n",
    "        zih = cP.norm(dim=0) + sP.norm(dim=0)\n",
    "        att_image = torch.zeros((image.camera.height, image.camera.width, 3))\n",
    "        att_image[v, u] = (hl * (torch.exp(-beta.detach().cpu() * zih) + B.detach().cpu() * (1 - torch.exp(-gamma.detach().cpu() * zih)))).T.clip(0, 1)\n",
    "        Image.fromarray(np.uint8(att_image * 255)).save(f'20150419T033711/att{iteration+1:05d}.png')\n",
    "        \n",
    "        rec = (hl * (J[v, u].T.detach().cpu() * torch.exp(-beta.detach().cpu() * zih) + B.detach().cpu() * (1 - torch.exp(-gamma.detach().cpu() * zih)))).T\n",
    "        rec_image = torch.zeros((image.camera.height, image.camera.width, 3))\n",
    "        rec_image[v, u] = rec.clip(0, 1)\n",
    "        Image.fromarray(np.uint8(rec_image * 255)).save(f'20150419T033711/rec{iteration+1:05d}.png')\n",
    "        \n",
    "        res_image = torch.zeros((image.camera.height, image.camera.width, 3))\n",
    "        res_image[v, u] = torch.abs(loader.load_image(image.image_path)[v, u] - rec)\n",
    "        Image.fromarray(np.uint8(plt.colormaps['jet'](res_image.mean(dim=2) * 5)[:, :, :3] * 255)).save(f'20150419T033711/res{iteration+1:05d}.png')\n",
    "        \n",
    "\n",
    "    for ui, vi, zi, Ii, ciP in data.iterbatch(batch_size=5):\n",
    "        \n",
    "        rand_args = torch.randperm(len(zi), device=device)[:int(len(zi) * 0.1)]\n",
    "        ui = ui[rand_args]\n",
    "        vi = vi[rand_args]\n",
    "        zi = zi[rand_args]\n",
    "        Ii = Ii[:, rand_args]\n",
    "        ciP = ciP[:, rand_args]\n",
    "        \n",
    "        siP = s_R_c @ ciP + s_t_c\n",
    "        sip = siP[:2] / siP[2]\n",
    "        \n",
    "        sip = sip.T.unsqueeze(dim=2)\n",
    "        halo = torch.exp(-(sip.transpose(1, 2) @ halocov.inverse() @ sip).flatten() / 2)\n",
    "        \n",
    "        zi = zi + siP.norm(dim=0)\n",
    "        \n",
    "        loss = torch.square(\n",
    "            Ii - halo * (J[vi, ui].T * torch.exp(-beta * zi) + B * (1 - torch.exp(-gamma * zi)))\n",
    "        ).sum()\n",
    "        \"\"\"loss = 2 * torch.nn.functional.huber_loss(\n",
    "            input=halo * (J[vi, ui].T * torch.exp(-beta * zi) + B * (1 - torch.exp(-gamma * zi))),\n",
    "            target=Ii,\n",
    "            reduction='sum',\n",
    "            delta=0.005\n",
    "        )\"\"\"\n",
    "        cost = cost + loss / size / 3\n",
    "    \n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    costs.append(cost.item())\n",
    "    with np.printoptions(precision=2):\n",
    "        \"\"\"print(f'cost: {cost.item():.3e}, B: {B.detach().flatten().cpu().numpy()}, beta: {beta.detach().flatten().cpu().numpy()}, '\n",
    "              f'gamma: {gamma.detach().flatten().cpu().numpy()}, t: {s_t_c.detach().flatten().cpu().numpy()}, '\n",
    "              f'w: {s_T_c[:3].detach().flatten().cpu().numpy()}, halocov: {halocov.detach().flatten().cpu().numpy()}')\"\"\"\n",
    "    \n",
    "    \"\"\"if (iteration + 1) % 1000 == 0:\n",
    "        im = J.detach().cpu().numpy().copy()\n",
    "        valid = loader.load_depth(image.depth_path).numpy() > 0\n",
    "        image_valid = im[valid]\n",
    "        image_valid = np.clip(image_valid, np.percentile(image_valid, 1, axis=0), np.percentile(image_valid, 99, axis=0))\n",
    "        image_valid = image_valid - np.min(image_valid, axis=0)\n",
    "        image_valid = image_valid / np.max(image_valid, axis=0)\n",
    "        im[~valid] = 0\n",
    "        im[valid] = image_valid\n",
    "        plt.imshow(im)\n",
    "        plt.savefig(f'halo2/grame{iteration:05d}.png')\n",
    "        plt.close()\n",
    "        \n",
    "        u, v, cP = image.unproject_depth_map(loader.load_depth(image.depth_path), transform=False)\n",
    "        sP = s_R_c.detach().cpu() @ cP + s_t_c.detach().cpu()\n",
    "        sp = sP[:2] / sP[2]\n",
    "        sp = sp.T.unsqueeze(dim=2)\n",
    "        hl = torch.exp(-(sp.transpose(1, 2) @ halocov.detach().cpu().inverse() @ sp).flatten() / 2)\n",
    "        #hl = hl - hl.min()\n",
    "        #hl = hl / hl.max()\n",
    "        hl_image = torch.zeros((image.camera.height, image.camera.width))\n",
    "        hl_image[v, u] = hl\n",
    "        plt.imshow(hl_image, cmap='jet')\n",
    "        plt.savefig(f'halo2/frame{iteration:05d}.png')\n",
    "        plt.close()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd4dc7c-e713-4028-b353-cdff1afd69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(data)\n",
    "\n",
    "for iteration in tqdm.tqdm(range(1001)):\n",
    "    \n",
    "    if iteration % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            im = J.cpu().numpy().copy()\n",
    "            valid = loader.load_depth(image.depth_path).numpy() > 0\n",
    "            image_valid = im[valid]\n",
    "            image_valid = np.clip(image_valid, np.percentile(image_valid, 1, axis=0), np.percentile(image_valid, 99, axis=0))\n",
    "            image_valid = image_valid - np.min(image_valid, axis=0)\n",
    "            image_valid = image_valid / np.max(image_valid, axis=0)\n",
    "            im[~valid] = 0\n",
    "            im[valid] = image_valid\n",
    "            im = Image.fromarray(np.uint8(im * 255))\n",
    "            draw = ImageDraw.Draw(im)\n",
    "            draw.text((15, 0), f'Iteration {iteration:02d}', (255, 255, 255), font=font, anchor='la')\n",
    "            im.save(f'eiffelanimation2/frame{iteration+1:05d}.png')\n",
    "\n",
    "            u, v, cP = image.unproject_depth_map(loader.load_depth(image.depth_path), transform=False)\n",
    "            s_R_c, s_t_c = se3_exp(s_T_c.cpu())\n",
    "            halocov = torch.stack([halostdx.cpu().square(), halocovxy.cpu(), halocovxy.cpu(), halostdy.cpu().square()]).view(2, 2)\n",
    "            sP = s_R_c @ cP + s_t_c\n",
    "            sp = sP[:2] / sP[2]\n",
    "            sp = sp.T.unsqueeze(dim=2)\n",
    "            hl = torch.exp(-(sp.transpose(1, 2) @ halocov.inverse() @ sp).flatten() / 2)\n",
    "            hl_image = torch.zeros((image.camera.height, image.camera.width))\n",
    "            hl_image[v, u] = hl\n",
    "            Image.fromarray(np.uint8(plt.colormaps['jet'](hl_image)[:, :, :3] * 255)).save(f'eiffelanimation2/halo{iteration+1:05d}.png')\n",
    "\n",
    "    for ui, vi, zi, Ii, ciP in data.iterbatch(batch_size=50):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        s_R_c, s_t_c = se3_exp(s_T_c)\n",
    "        halocov = torch.stack([halostdx.square(), halocovxy, halocovxy, halostdy.square()]).view(2, 2)\n",
    "        \n",
    "        siP = s_R_c @ ciP + s_t_c\n",
    "        sip = siP[:2] / siP[2]\n",
    "        \n",
    "        sip = sip.T.unsqueeze(dim=2)\n",
    "        halo = torch.exp(-(sip.transpose(1, 2) @ halocov.inverse() @ sip).flatten() / 2)\n",
    "        \n",
    "        zi = zi + siP.norm(dim=0)\n",
    "        \n",
    "        loss = torch.square(\n",
    "            Ii - halo * (J[vi, ui].T * torch.exp(-beta * zi) + B * (1 - torch.exp(-gamma * zi)))\n",
    "        ).sum() / size / 3\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with np.printoptions(precision=2):\n",
    "        \"\"\"print(f'cost: {cost.item():.3e}, B: {B.detach().flatten().cpu().numpy()}, beta: {beta.detach().flatten().cpu().numpy()}, '\n",
    "              f'gamma: {gamma.detach().flatten().cpu().numpy()}, t: {s_t_c.detach().flatten().cpu().numpy()}, '\n",
    "              f'w: {s_T_c[:3].detach().flatten().cpu().numpy()}, halocov: {halocov.detach().flatten().cpu().numpy()}')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c01032-e3ee-44d1-9a44-735aa52f63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(4, 2.1), layout='constrained')\n",
    "hl_plot = ax.imshow(hl_image, vmin=0, vmax=1, cmap='jet')\n",
    "ax.axis('off')\n",
    "cbar = fig.colorbar(hl_plot, shrink=0.89, pad=0.02)\n",
    "#cbar.set_label('Halo intensity', rotation=270, labelpad=10)\n",
    "cbar.locator = matplotlib.ticker.MaxNLocator(nbins=6)\n",
    "cbar.ax.tick_params(length=2)\n",
    "cbar.update_ticks()\n",
    "fig.savefig(f'halo.pdf', bbox_inches='tight', pad_inches=0, dpi=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959e6675-30bc-4d94-80bc-a83a115f2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(np.uint8(im * 255)).save('20220420T124924.000Z_sucre.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463ae093-8349-45d9-ab02-a2cdcf8f21a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(im[:, :, 1].flatten(), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd8c9ba-850c-4329-9e96-b4ad9b773fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960bab0-5c4c-4bfb-94a4-f8454179c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "v, u = torch.where(loader.load_depth(image.depth_path) > -1)\n",
    "uvw = torch.stack([u + 0.5, v + 0.5, torch.ones_like(u)])\n",
    "cp = uvw * 10\n",
    "cP = image.camera.K_inv @ cp\n",
    "\n",
    "s_R_c, s_t_c = se3_exp(si_T_ci.detach().cpu())\n",
    "sP = s_R_c @ cP + s_t_c\n",
    "sp = sP[:2] / sP[2]\n",
    "\n",
    "hl = coeffs[0].detach().cpu() + coeffs[1].detach().cpu() * sp[0].square() + coeffs[2].detach().cpu() * sp[1].square()\n",
    "plt.imshow(hl.reshape(image.camera.height, image.camera.width), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e918e88-d4fa-4d7a-a8f7-33b2cf5b3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = np.linspace(-0.5, 0.5, 300)\n",
    "spx, spy = np.meshgrid(sp, sp)\n",
    "sP = np.stack([spx.flatten(), spy.flatten(), np.ones_like(spx.flatten())])\n",
    "hl = coeffs[0].detach().cpu().numpy() + coeffs[1].detach().cpu().numpy() * sP[0].square() + coeffs[2].detach().cpu().numpy() * sP[1].square()\n",
    "\n",
    "r, t = se3_exp(si_T_ci.detach().cpu())\n",
    "t = -r.T @ t\n",
    "t = t.numpy()\n",
    "r = r.T.numpy()\n",
    "\n",
    "cp = image.camera.K.numpy() @ (r @ sP + t)\n",
    "cp = cp[:2] / cp[2]\n",
    "\n",
    "plt.scatter(*cp, s=0.1, c=hl, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba7a39-392a-4e72-be18-7fa8ab1467e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4825d5d-0ef9-4d86-a452-4ec43822daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Jg.detach().cpu().numpy().copy()\n",
    "valid = loader.load_depth(image.depth_path).numpy() > 0\n",
    "image_valid = im[valid]\n",
    "image_valid = np.clip(image_valid, np.percentile(image_valid, 1, axis=0), np.percentile(image_valid, 99, axis=0))\n",
    "image_valid = image_valid - np.min(image_valid, axis=0)\n",
    "image_valid = image_valid / np.max(image_valid, axis=0)\n",
    "im[~valid] = 0\n",
    "im[valid] = image_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b07691-1851-4948-b0c1-a541781f02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaef818-c4f5-48a4-99ce-27165198db71",
   "metadata": {},
   "source": [
    "## Halo analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af2c0c-9e0a-4496-bde7-37c151b486d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "x, y = np.meshgrid(np.linspace(-5, 5, 100), np.linspace(-5, 5, 100))\n",
    "x = x.flatten()\n",
    "y = y.flatten()\n",
    "sp = torch.tensor(np.stack([x, y]).T[..., None], dtype=torch.float32)\n",
    "halocov = torch.tensor([\n",
    "    [1.0, -0.9],\n",
    "    [-0.9, 2.0]\n",
    "])\n",
    "hl = torch.exp(-(sp.transpose(1, 2) @ halocov.inverse() @ sp).flatten() / 2) / (2 * np.pi * halocov.det().sqrt())\n",
    "plt.scatter(sp[:, 0, 0].numpy(), sp[:, 1, 0], c=hl.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f283d1-7ab6-49a3-8880-140ca185360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_mesh = o3d.io.read_triangle_mesh('camera.obj')\n",
    "\n",
    "camera = o3d.geometry.TriangleMesh(camera_mesh)\n",
    "camera.paint_uniform_color([0, 0.709, 0])\n",
    "cameras = [camera]\n",
    "\n",
    "i, j = np.meshgrid(np.linspace(-np.pi / 4, np.pi / 4, 4), np.linspace(-np.pi / 4, np.pi / 4, 4))\n",
    "i = i.flatten()\n",
    "j = j.flatten()\n",
    "for a, b in zip(i, j):\n",
    "    R, t = se3_exp(torch.tensor([a, b, 0.0, 0.0, 0.0, 0.0]))\n",
    "    camera = o3d.geometry.TriangleMesh(camera_mesh)\n",
    "    camera.paint_uniform_color([0.709, 0, 0])\n",
    "    camera.transform(np.vstack([\n",
    "        np.hstack([R.numpy(), t.numpy()]),\n",
    "        [0, 0, 0, 1]\n",
    "    ]))\n",
    "    cameras.append(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec59348d-c865-455d-8359-d4265f751646",
   "metadata": {},
   "source": [
    "w3 is roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843365d9-002d-47de-bb03-985893a61bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(cameras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf433e-dc5c-4474-8014-222080c48b41",
   "metadata": {},
   "source": [
    "## Plot spot trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05fdc1d-fb47-4cd8-b77d-d4b10c1279e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_mesh = o3d.io.read_triangle_mesh('camera.obj')\n",
    "cameras = []\n",
    "for i, (R, t) in enumerate(zip(Rs, ts)):\n",
    "    camera = o3d.geometry.TriangleMesh(camera_mesh)\n",
    "    if i == 0:\n",
    "        camera.paint_uniform_color([0, 0.709, 0])\n",
    "    else:\n",
    "        camera.paint_uniform_color([0.709, 0, 0])\n",
    "    camera.transform(np.vstack([\n",
    "        np.hstack([0.1 * R, t]),\n",
    "        [0, 0, 0, 1]\n",
    "    ]))\n",
    "    cameras.append(camera)\n",
    "o3d.visualization.draw_geometries(cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664ff4c-04f9-4414-a233-75f43227102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "2000000*10000000*4 / (10**12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58176ffc-ca6a-4f51-bfac-fd4d10db5c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
